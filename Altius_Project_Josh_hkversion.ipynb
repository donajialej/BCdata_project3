{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read data as dataframe\n",
    "df = pd.read_csv(\"/home/hildurk/data/3-Simon/promoterDHS_distalDHS_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Define a function to convert a chromosome string to a genomic sequence\n",
    "def chrom2seq(chrom):\n",
    "    \"\"\"Convert chromosome string \"chrom\" to a genomic sequence\"\"\"\n",
    "\n",
    "    return list(SeqIO.parse(\n",
    "        \"/home/hildurk/data/3-Simon/hg38.analysisSet.chroms/%s.fa\" % chrom, \"fasta\"))[0].seq.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom2seq('chr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of chromosomes\n",
    "CHROMS = [\"chr1\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\", \"chr15\", \"chr16\", \"chr17\", \n",
    "          \"chr18\", \"chr19\", \"chr2\", \"chr20\", \"chr21\", \"chr22\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \n",
    "          \"chr7\", \"chr8\", \"chr9\", \"chrM\", \"chrX\", \"chrY\"]\n",
    "\n",
    "# Make dictionary\n",
    "CHROM2SEQ = dict(zip(CHROMS,[chrom2seq(chrom) for chrom in CHROMS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = CHROM2SEQ['chr1'][925589:925790]\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to create a one-hot encoding for a genomic sequence\n",
    "base2row = {'A':0,'C':1,'G':2,'T':3}\n",
    "def seq2onehot(seq):\n",
    "    \"\"\"Create a one-hot encoding of a nucleotide sequence\"\"\"\n",
    "    \n",
    "    A = np.zeros((len(seq),4),dtype=bool)\n",
    "    for i, base in enumerate(seq):\n",
    "        if base=='N':\n",
    "            continue\n",
    "        A[i,base2row[base]] = True\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1h = seq2onehot(seq)\n",
    "np.shape(seq1h)\n",
    "print(seq1h[:5,:])\n",
    "seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to find the reverse compliment of a one-hot encoding\n",
    "def onehot2rc(onehot):\n",
    "    \"\"\"Find the one-hot encoding of the reverse compliment\n",
    "    of the genomic sequence with one-hot encoding onehot\"\"\"\n",
    "    \n",
    "    A = np.flipud(onehot) # First reverse\n",
    "    A = np.fliplr(A) # Then take compliment (i.e. switch A&T and C&G)\n",
    "    #B = np.zeros(np.shape(A),dtype=bool)\n",
    "    #B[:,0], B[:,1], B[:,2], B[:,3] = A[:,1], A[:,0], A[:,3], A[:,2]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = seq1h[:5,:]\n",
    "B = onehot2rc(A)\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sample the same number of linked==1 class as linked==0 class\n",
    "idx1 = np.where(df[\"linked\"])[0]\n",
    "idx0 = np.where(df[\"linked\"]==0)[0]\n",
    "np.random.shuffle(idx1)\n",
    "np.random.shuffle(idx0)\n",
    "\n",
    "nsamples_per_class = 20000\n",
    "print(np.shape(idx1))\n",
    "print(np.shape(idx0))\n",
    "idx1 = idx1[:nsamples_per_class]\n",
    "idx0 = idx0[:nsamples_per_class]\n",
    "print(np.shape(idx1))\n",
    "print(np.shape(idx0))\n",
    "\n",
    "# Save these indices\n",
    "np.savez(\"/home/hildurk/BCdata_project3/SampleIdx.npz\",\n",
    "         idx1=idx1, idx0=idx0)\n",
    "\"\"\"\n",
    "# Load idx1 and idx0 if saved\n",
    "sample_idx = np.load(\"/home/hildurk/BCdata_project3/SampleIdx.npz\")\n",
    "idx1, idx0 = sample_idx['idx1'], sample_idx['idx0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([idx1, idx0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a sample\n",
    "idx10 = np.concatenate([idx1,idx0])\n",
    "np.random.shuffle(idx10)\n",
    "newdf = df.iloc[idx10]\n",
    "del df\n",
    "df = newdf\n",
    "del newdf\n",
    "\n",
    "#df = df.sample(n=10000) # Comment this out when loading indices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for promoter length and distal length\n",
    "df[\"promoter_len\"] = df[\"promoterDHSend\"]-df[\"promoterDHSstart\"]\n",
    "df[\"distal_len\"] = df[\"distalDHSend\"]-df[\"distalDHSstart\"]\n",
    "\n",
    "# Plot histogram of sequence lengths\n",
    "plt.figure\n",
    "plt.hist(df[\"promoter_len\"],bins=30,color=\"r\",alpha=0.4,label=\"promoter\")\n",
    "plt.hist(df[\"distal_len\"],bins=30,color=\"b\",alpha=0.4,label=\"distal\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"base pair\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a maximum sequence length and filter out longer sequences\n",
    "seqlength = 2000\n",
    "df = df[(df[\"promoter_len\"]<seqlength) & (df[\"distal_len\"]<seqlength)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize one-hot encoding arrays (X)\n",
    "N = df.shape[0]\n",
    "encoding_promoter = np.zeros((N,seqlength,2,4),dtype=bool)\n",
    "encoding_distal = np.zeros((N,seqlength,2,4),dtype=bool)\n",
    "\n",
    "# Initialize Y\n",
    "Y = np.zeros((N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X (one-hot encoding) and Y (linked) for Keras\n",
    "row_no = 0\n",
    "for i,row in df.iterrows():\n",
    "    seq_promoter = CHROM2SEQ[row.chr][row.promoterDHSstart:row.promoterDHSend]\n",
    "    seq_distal = CHROM2SEQ[row.chr][row.distalDHSstart:row.distalDHSend]\n",
    "    try:\n",
    "        onehot_promoter = seq2onehot(seq_promoter)\n",
    "        onehot_distal = seq2onehot(seq_distal)\n",
    "        encoding_promoter[row_no,:row.promoter_len,0,:] = onehot_promoter\n",
    "        encoding_distal[row_no,:row.distal_len,0,:] = onehot_distal\n",
    "        encoding_promoter[row_no,:row.promoter_len,1,:] = onehot2rc(onehot_promoter)\n",
    "        encoding_distal[row_no,:row.distal_len,1,:] = onehot2rc(onehot_distal)\n",
    "        Y[row_no] = row.linked\n",
    "        row_no += 1\n",
    "    except KeyError:\n",
    "        print(seq_promoter)\n",
    "        print(seq_distal)\n",
    "        break\n",
    "        \n",
    "del onehot_promoter\n",
    "del onehot_distal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(encoding_promoter))\n",
    "print(np.shape(encoding_distal))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"Test whether we can predict promoter and distal sequences using model\n",
    "\n",
    "X = np.zeros((2*N,seqlength,2,4),dtype=bool)\n",
    "Y = np.zeros((2*N,1),dtype=bool)\n",
    "X[:N,:,:,:] = encoding_promoter\n",
    "X[N:,:,:,:] = encoding_distal\n",
    "Y[:N] = np.ones((N,1),dtype=bool)\n",
    "\n",
    "# Create training, development and test data sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.25)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train, y_train, test_size=0.33)\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Create training, development and test data sets\n",
    "\n",
    "train_idx, test_idx, y_train, y_test = train_test_split(\n",
    "    np.arange(N), Y, test_size=0.25)\n",
    "\n",
    "train_idx, dev_idx, y_train, y_dev = train_test_split(\n",
    "    train_idx, y_train, test_size=0.33)\n",
    "\n",
    "# Save these so that we don't keep getting new training and test sets\n",
    "\n",
    "np.savez(\"/home/hildurk/BCdata_project3/TrainDevTest.npz\",\n",
    "         train_idx=train_idx, dev_idx=dev_idx, test_idx=test_idx,\n",
    "        y_train=y_train, y_dev=y_dev, y_test=y_test)\n",
    "\n",
    "\"\"\"\n",
    "# Load saved train, dev, test indices and y vectors\n",
    "TrainDevTest = np.load(\"/home/joshscurll/bcdata_Altius_Project/BCdata_project3/TrainDevTest.npz\")\n",
    "train_idx, dev_idx, test_idx = TrainDevTest['train_idx'], TrainDevTest['dev_idx'], TrainDevTest['test_idx']\n",
    "y_train, y_dev, y_test = TrainDevTest['y_train'], TrainDevTest['y_dev'], TrainDevTest['y_test']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xp_train = encoding_promoter[train_idx,:,:]\n",
    "xp_dev = encoding_promoter[dev_idx,:,:]\n",
    "xp_test = encoding_promoter[test_idx,:,:]\n",
    "\n",
    "xd_train = encoding_distal[train_idx,:,:]\n",
    "xd_dev = encoding_distal[dev_idx,:,:]\n",
    "xd_test = encoding_distal[test_idx,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Conv1D, Conv2D, GlobalMaxPooling1D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.constraints import non_neg\n",
    "from keras import regularizers as regs\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some functions for the model\n",
    "\n",
    "def reluConv2D(x, filters, kernel_size, name):\n",
    "    return Conv2D(filters=filters, kernel_size=(kernel_size,1),\n",
    "                 activation='relu', padding='same', name=name,\n",
    "                  kernel_constraint=non_neg(),\n",
    "                 kernel_regularizer=regs.l1(0.001))(x)\n",
    "\n",
    "def gmp2d(x):\n",
    "    return GlobalMaxPooling2D()(x)\n",
    "\n",
    "\"\"\"\n",
    "def columnwise_mp(x):\n",
    "    return MaxPooling2D(pool_size=(int(np.shape(x)[1]),1))(x)\n",
    "    #return MaxPooling2D(pool_size=(2000,1))(x)\n",
    "\n",
    "def reluConv1D(x, filters, kernel_size, name):\n",
    "    return Conv1D(filters=filters, kernel_size=kernel_size, \n",
    "                  activation='relu', padding='same', name=name)(x)\n",
    "\n",
    "def gmp1d(x):\n",
    "    return GlobalMaxPooling1D()(x)\n",
    "\"\"\"\n",
    "\n",
    "def convMP(x, filters, kernel_size, name):\n",
    "    return gmp2d(reluConv2D(x, filters, kernel_size, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoding_promoter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "X = tf.stack(encoding_promoter[:10,:,:,:].astype(float))\n",
    "Xconv = reluConv2D(X,3,4,'TestConv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Xconvgmp = gmp2d(Xconv)\n",
    "np.shape(Xconvgmp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Xconvmp = columnwise_mp(Xconv)\n",
    "np.shape(Xconvmp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"# Specify the model\n",
    "onehot = Input(shape=(seqlength,2,4),name='promoterDHSoh')\n",
    "fingerprint = convMP(onehot,24,6,'ConvPromoterDHS')\n",
    "prob_association = Dense(1,activation='sigmoid',name='logistic_regr')(fingerprint)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_encoding_promoter = Input(shape=(seqlength,2,4),name='promDHSoh') #oh is one hot\n",
    "one_hot_encoding_distal = Input(shape=(seqlength,2,4),name='distalDHSoh') #oh is one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_filters = 20 #temp, we'll change it later\n",
    "filter_len = 6 #temp, we'll change it later\n",
    "\n",
    "#conv_layer_distal = Conv1D(nb_filters,filter_len,padding='same',name='distalDHSconv',activation='relu')(one_hot_encoding_distal)\n",
    "fingerprint_distal = convMP(one_hot_encoding_distal,nb_filters,filter_len,'distalDHSconv')#GlobalMaxPooling1D()(conv_layer_distal)\n",
    "\n",
    "#conv_layer_promoter = Conv1D(nb_filters,filter_len,padding='same',name='promDHSconv',activation='relu')(one_hot_encoding_promoter)\n",
    "fingerprint_promoter = convMP(one_hot_encoding_promoter,nb_filters,filter_len,'promDHSconv')#GlobalMaxPooling1D()(conv_layer_promoter)\n",
    "\n",
    "merged_vector = keras.layers.concatenate([fingerprint_distal,fingerprint_promoter],axis=-1)\n",
    "prob_association = Dense(1,activation='sigmoid',name='logistic_regression')(merged_vector) #one neuron logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[one_hot_encoding_distal,one_hot_encoding_promoter],outputs=prob_association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=onehot,outputs=prob_association)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the percentage of nonzeros in Y\n",
    "#pc = len(np.where(Y)[0]) / len(Y)\n",
    "#print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['mse','accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='PD_RC_20nf_lambda0001.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit the model using a dictionary to weight class 1 more highly than class 0\n",
    "so that both classes are represented equally in the model fitting\n",
    "\"\"\"\n",
    "import sklearn\n",
    "#class_weight = {0: 1, 1: min([1./pc-1.,50])}\n",
    "#class_weight_vec = sklearn.utils.class_weight.compute_class_weight('balanced',[0.,1.],Y)\n",
    "model.fit([xd_train,xp_train],y_train,batch_size=256,epochs=50,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[EarlyStopping(patience=3),checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PD_RC_20nf_lambda0001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('PD_RC_20nf_lambda0001.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizing the filters\n",
    "\"\"\"\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "filters=model.get_layer('promDHSconv').get_weights()[0]\n",
    "fig, axs = plt.subplots(int(np.ceil(np.shape(filters)[3]/3)),3, figsize=(20, 15), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(np.shape(filters)[3]):\n",
    "    im=axs[i].imshow(filters[:,0,:,i].T)\n",
    "    plt.colorbar(im,ax=axs[i])\n",
    "#plt.title('Filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizing the filters\n",
    "\"\"\"\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "filters=model.get_layer('distalDHSconv').get_weights()[0]\n",
    "fig, axs = plt.subplots(int(np.ceil(np.shape(filters)[3]/3)),3, figsize=(20, 15), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(np.shape(filters)[3]):\n",
    "    im=axs[i].imshow(filters[:,0,:,i].T)\n",
    "    plt.colorbar(im,ax=axs[i])\n",
    "#plt.title('Filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the beta values\n",
    "\"\"\"\n",
    "beta=model.get_layer('logistic_regression').get_weights()[0]\n",
    "print(beta[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ROC score\n",
    "\"\"\"\n",
    "print('Predicting on development data...')\n",
    "y_score = model.predict([xd_test,xp_test])\n",
    "score=roc_auc_score(y_test, y_score, average='macro', sample_weight=None)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\"\"\"\n",
    "ROC score\n",
    "\"\"\"\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.show()\n",
    "print('AUC: %f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(seq_promoter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
