{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the normal way of getting data\n",
    "'''\n",
    "df = pd.read_csv(\"~/data/3-Simon/promoterDHS_distalDHS_pairs.csv\")\n",
    "df = df.sample(n=50000)\n",
    "df['promoter_len'] = df['promoterDHSend']-df['promoterDHSstart']\n",
    "df['distal_len'] = df['distalDHSend'] - df['distalDHSstart']\n",
    "'''\n",
    "#but we'll use josh's indices which are balanced already\n",
    "sample_idx = np.load(\"/home/pau557/BCdata_project3/SampleIdx.npz\")\n",
    "idx1, idx0 = sample_idx['idx1'], sample_idx['idx0']\n",
    "np.concatenate([idx1, idx0])\n",
    "idx10 = np.concatenate([idx1,idx0])\n",
    "np.random.shuffle(idx10)\n",
    "df = pd.read_csv(\"~/data/3-Simon/promoterDHS_distalDHS_pairs.csv\")\n",
    "newdf = df.iloc[idx10]\n",
    "del df\n",
    "df = newdf\n",
    "del newdf\n",
    "df['promoter_len'] = df['promoterDHSend']-df['promoterDHSstart']\n",
    "df['distal_len'] = df['distalDHSend'] - df['distalDHSstart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "plt.hist(df['promoter_len'],bins=30,color='g',alpha=0.4,label='promoter')\n",
    "plt.hist(df['distal_len'],bins=30,color='r',alpha=0.4, label='distal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqlength = 2000\n",
    "df = df[(df['promoter_len']<seqlength)&(df['distal_len']<seqlength)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.zeros((df.shape[0]),dtype=int)\n",
    "c = 0\n",
    "for i, row in df.iterrows():\n",
    "    Y[c]=int(row.linked)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight_vec = sklearn.utils.class_weight.compute_class_weight('balanced',[0.,1.],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_weight_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = df.shape[0]\n",
    "encoding_promoter = np.zeros((N,seqlength*2,4),dtype=bool)\n",
    "encoding_distal = np.zeros((N,seqlength*2,4),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def chrom2seq(chrom):\n",
    "    \"\"\"\n",
    "    Convert chromosome string \"chrom\" to a genomic sequence\n",
    "    \"\"\"\n",
    "\n",
    "    return list(SeqIO.parse(\n",
    "        \"/home/pau557/data/3-Simon/hg38.analysisSet.chroms/%s.fa\" % chrom, \"fasta\"))[0].seq.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom2seq('chr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of chromosomes\n",
    "CHROMS = [\"chr1\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\", \"chr15\", \"chr16\", \"chr17\", \n",
    "          \"chr18\", \"chr19\", \"chr2\", \"chr20\", \"chr21\", \"chr22\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \n",
    "          \"chr7\", \"chr8\", \"chr9\", \"chrM\", \"chrX\", \"chrY\"]\n",
    "\n",
    "# Make dictionary\n",
    "CHROM2SEQ = dict(zip(CHROMS,[chrom2seq(chrom) for chrom in CHROMS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = CHROM2SEQ['chr1'][925589:925790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "base2row = {'A':0,'C':1,'G':2,'T':3}\n",
    "def double_seq2onehot(seq):\n",
    "    \"\"\"\n",
    "    Create a one-hot encoding of a nucleotide sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.zeros((len(seq)*2,4),dtype=bool)\n",
    "    \n",
    "    for i, base in enumerate(seq):\n",
    "        if base == 'N': continue\n",
    "        A[i,base2row[base]] = True\n",
    "        \n",
    "    for i, base in enumerate(seq[::-1]):\n",
    "        if base == 'N': continue\n",
    "        A[i+len(seq),base2row[base]] = True\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i, row in df.iterrows():\n",
    "    encoding_promoter[c,:row.promoter_len*2,:]=double_seq2onehot(CHROM2SEQ[row.chr][row.promoterDHSstart:row.promoterDHSend])\n",
    "    encoding_distal[c,:row.distal_len*2,:]=double_seq2onehot(CHROM2SEQ[row.chr][row.distalDHSstart:row.distalDHSend])\n",
    "    c += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll start from a logistic regression of weather a dital region is an enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_encoding_promoter = Input(shape=(seqlength*2,4),name='promDHSoh') #oh is one hot\n",
    "one_hot_encoding_distal = Input(shape=(seqlength*2,4),name='distalDHSoh') #oh is one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.constraints import non_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_filters = 12 #temp, we'll change it later\n",
    "filter_len = 6 #temp, we'll change it later\n",
    "\n",
    "conv_layer_distal = Conv1D(nb_filters,filter_len,padding='same',name='distalDHSconv',activation='relu',kernel_regularizer=regularizers.l1(0.0001),kernel_constraint=non_neg())(one_hot_encoding_distal)\n",
    "fingerprint_distal = GlobalMaxPooling1D()(conv_layer_distal)\n",
    "\n",
    "conv_layer_promoter = Conv1D(nb_filters,filter_len,padding='same',name='promDHSconv',activation='relu',kernel_regularizer=regularizers.l1(0.0001),kernel_constraint=non_neg())(one_hot_encoding_promoter)\n",
    "fingerprint_promoter = GlobalMaxPooling1D()(conv_layer_promoter)\n",
    "\n",
    "merged_vector = keras.layers.concatenate([fingerprint_distal,fingerprint_promoter],axis=-1)\n",
    "deeplayer1 = Dense(20,activation='relu',name='deeplayer1')(merged_vector)\n",
    "deeplayer2 = Dense(20,activation='relu',name='deeplayer2')(deeplayer1)\n",
    "\n",
    "prob_association = Dense(1,activation='sigmoid',name='logistic_regression')(deeplayer2)\n",
    "#one neuron logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[one_hot_encoding_distal,one_hot_encoding_promoter],outputs=prob_association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this resets the model, but later on there is a box where you can load the values from a previous run\n",
    "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ind, test_ind, y_train, y_test = train_test_split(range(len(Y)), Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_promoter_train = encoding_promoter[train_ind,:,:]\n",
    "X_promoter_test = encoding_promoter[test_ind,:,:]\n",
    "\n",
    "X_distal_train = encoding_distal[train_ind,:,:]\n",
    "X_distal_test = encoding_distal[test_ind,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('pau_model', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to continue from a saved model instead of resetting everything\n",
    "from keras.models import load_model\n",
    "model = load_model('pau_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit([X_distal_train,X_promoter_train], y_train, batch_size=250, epochs=30, validation_split=0.2,class_weight={0:class_weight_vec[0],1:class_weight_vec[1]},callbacks=[early_stopping,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizing the distal filters\n",
    "\"\"\"\n",
    "filters=model.get_layer('distalDHSconv').get_weights()[0]\n",
    "fig, axs = plt.subplots(3,4, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(12):\n",
    "    im=axs[i].imshow(filters[:,:,i].T)\n",
    "    #plt.yticks(range(4),['A','T','C','G'])\n",
    "    plt.colorbar(im,ax=axs[i])\n",
    "plt.title('Filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizing the distal filters\n",
    "\"\"\"\n",
    "filters=model.get_layer('promDHSconv').get_weights()[0]\n",
    "fig, axs = plt.subplots(3,4, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(12):\n",
    "    im=axs[i].imshow(filters[:,:,i].T)\n",
    "    #plt.yticks(range(4),['A','T','C','G'])\n",
    "    plt.colorbar(im,ax=axs[i])\n",
    "plt.title('Filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ROC score\n",
    "\"\"\"\n",
    "#y_score = model.predict_proba(xd_dev, verbose=0)\n",
    "print('Predicting on test data')\n",
    "y_score = model.predict([X_distal_test,X_promoter_test])\n",
    "score=roc_auc_score(y_test, y_score, average='macro', sample_weight=None)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.pearsonr(y_test,np.array(y_score.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test,np.array(y_score.T[0]),alpha=0.01,marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at Keras Merge for enhancers and promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\"\"\"\n",
    "ROC score\n",
    "\"\"\"\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.show()\n",
    "print('AUC: %f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model for testing associations. \n",
    "it's the same model as before but this time the input layer is the merged convolutions. so you can fire filters as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_conv = Input(shape=(1,24),name='input_for_association_test')\n",
    "deeplayer1_2 = model.get_layer('deeplayer1')(merged_conv)\n",
    "deeplayer2_2 = model.get_layer('deeplayer2')(deeplayer1_2)\n",
    "\n",
    "prob_association_2 = model.get_layer('logistic_regression')(deeplayer2_2)\n",
    "model2 = Model(inputs=merged_conv,outputs=prob_association_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_predictor = np.zeros((24*24,1,24))\n",
    "c = 0\n",
    "for i in range(24):\n",
    "    for j in range(24):\n",
    "        association_predictor[c][0][i]=1\n",
    "        association_predictor[c][0][j]=1\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model2.predict(association_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "association_matrix = np.zeros((24,24))\n",
    "c = 0\n",
    "for i in range(24):\n",
    "    for j in range(24):\n",
    "        association_matrix[i][j]=y_score[c]\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(association_matrix,interpolation='none',cmap='gray')\n",
    "plt.axvline(11.5,color='r')\n",
    "plt.axhline(11.5,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
